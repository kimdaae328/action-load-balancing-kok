# 로드 밸런싱 (Load Balancing)

## 개요

**로드 밸런싱(Load Balancing)** 은 사용자의 요청(트래픽)을 여러 서버로 분산시켜  
시스템의 **부하를 균등하게 분배**하고, **서비스 안정성과 가용성**을 높이는 기술이다.  

즉, 한 서버에만 요청이 몰려 다운되거나 느려지는 문제를 방지하고  
여러 서버가 협력하여 하나의 서비스처럼 동작하도록 한다.

---

## 주요 개념

| 개념 | 설명 |
|------|------|
| **Load Balancer (LB)** | 클라이언트 요청을 여러 서버에 분산시키는 중간 관리자 역할 |
| **Target Group** | 로드 밸런서가 분산시킬 대상 서버(EC2, 컨테이너 등)의 집합 |
| **Health Check** | 서버의 상태를 주기적으로 점검하여, 정상인 서버로만 트래픽을 전달 |
| **Session Persistence** | 사용자의 세션이 특정 서버에 고정되도록 설정하는 옵션 (필요 시) |

---

## 로드 밸런싱 구조 예시
- **로드 밸런서 (AWS ELB 또는 Nginx)**  
  → 트래픽을 두 개 이상의 EC2 인스턴스(Spring 서버)로 분산  

- **EC2 서버**  
  → 각각 Docker 컨테이너로 Spring Boot 애플리케이션을 실행  

- **RDS / Redis**  
  → 모든 서버가 공유하는 데이터베이스 및 캐시 서버


## 동작 방식

1. 사용자가 서비스에 접속하면 요청이 **로드 밸런서로 먼저 전달**된다.  
2. 로드 밸런서는 **서버의 상태(Health Check)** 를 확인한다.  
3. 정상 상태인 서버 중 하나를 선택해 트래픽을 전달한다.  
4. 한 서버에 과부하가 발생하면 다른 서버로 요청을 분산시킨다.  
5. 서버 한 대가 다운되더라도 나머지 서버가 서비스를 계속 유지한다.

---

## Nginx 로드 밸런싱 설정 예시

```nginx
http {
    upstream backend {
        server 172.31.0.101:10000;  # Spring 1
        server 172.31.0.102:10000;  # Spring 2
    }

    server {
        listen 80;
        location / {
            proxy_pass http://backend;
        }
    }
}
```

💡 **upstream** 블록에서 여러 서버를 등록하면  
Nginx가 자동으로 트래픽을 균등하게 분배한다.

## 기대 효과

- 트래픽 폭주 시에도 **서비스 안정성 유지**  
- 서버 간 **부하 분산으로 성능 향상**  
- 서버 장애 발생 시 **자동 장애 대응 (Failover)**  
- **확장성(Scalability)** 확보로 **무중단 배포** 가능  

---

## CI/CD 워크플로우 단계
<img width="2560" height="1440" alt="cicd2" src="https://github.com/user-attachments/assets/b9a9ff12-12d2-4018-a7e8-1cac09e27b61" />
